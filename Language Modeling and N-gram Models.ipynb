{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "gFd5yIjjy9bJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f226X1Tcpura",
        "outputId": "f9ce1d0b-9ceb-495d-f2ab-46294497c1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categories_list = [[\"Ankara\", \"Bursa\", \"İstanbul\", \"İzmir\"]]\n",
        "\n",
        "# One-Hot Encoding işlemi\n",
        "encoder = OneHotEncoder(categories=categories_list, sparse_output=False)\n",
        "\n",
        "\n",
        "cities = [[\"İstanbul\"], [\"Ankara\"], [\"İzmir\"], [\"Bursa\"]]\n",
        "one_hot = encoder.fit_transform(cities)\n",
        "\n",
        "print(one_hot)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj1S_lmouugJ",
        "outputId": "1885cc9f-b337-4765-98d7-49c107f46f6a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Encoding**"
      ],
      "metadata": {
        "id": "3Puowvk8zHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC0gbaFqu7lG",
        "outputId": "bc7f0a75-3cd6-4762-8dea-ea3d5723099c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category-encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDrZkRJFuzOF",
        "outputId": "220e4ecf-71fc-44a5-d489-4afab526466b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category-encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category-encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category-encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category-encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category-encoders) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "df = pd.DataFrame({\"Şehir\": [\"İstanbul\", \"Ankara\", \"İzmir\", \"Bursa\", \"Ankara\", \"İstanbul\"]})\n",
        "\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=[\"Şehir\"])\n",
        "\n",
        "# Binary Encoding işlemi\n",
        "df_encoded = encoder.fit_transform(df)\n",
        "\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcPIJRGYvAj9",
        "outputId": "55158c0b-1460-452b-f811-ec340df5651f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Şehir_0  Şehir_1  Şehir_2\n",
            "0        0        0        1\n",
            "1        0        1        0\n",
            "2        0        1        1\n",
            "3        1        0        0\n",
            "4        0        1        0\n",
            "5        0        0        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words Modeli**"
      ],
      "metadata": {
        "id": "gknwIrSKzMh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.Boolean(İkili)Skorlama(0 ve 1 kullanımı)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9KY4ggubzT_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "documents = [\n",
        "    \"It was the best of times\",\n",
        "    \"it was the worst of times\",\n",
        "    \"it was the age of wisdom\",\n",
        "    \"it was the age of foolishness\"\n",
        "]\n",
        "\n",
        "# BoW modelini oluştur\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Kelime Sözlüğü:\", vectorizer.get_feature_names_out())\n",
        "print(\"BoW Matrisi:\\n\", X.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNK8bEpovDRM",
        "outputId": "24f15f96-50ff-43c4-d396-1443ee1dfeb0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelime Sözlüğü: ['age' 'best' 'foolishness' 'it' 'of' 'the' 'times' 'was' 'wisdom' 'worst']\n",
            "BoW Matrisi:\n",
            " [[0 1 0 1 1 1 1 1 0 0]\n",
            " [0 0 0 1 1 1 1 1 0 1]\n",
            " [1 0 0 1 1 1 0 1 1 0]\n",
            " [1 0 1 1 1 1 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "2.Count (Kelime Freknas) Skorlama\n",
        "\n"
      ],
      "metadata": {
        "id": "qEEY2hayzlX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "documents = [\n",
        "    \"Kedi hızlıdır ve kedi koşar.\",\n",
        "    \"Kedi çok sevimlidir.\",\n",
        "    \"Köpek havlar, kedi miyavlar.\"\n",
        "]\n",
        "\n",
        "# BoW modeli (Kelime frekansları ile)\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Kelime Sözlüğü:\", vectorizer.get_feature_names_out())\n",
        "print(\"BoW Matrisi:\\n\", X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7EhKzwMvG0f",
        "outputId": "15160424-80c4-47a0-da99-61fceee67c7e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelime Sözlüğü: ['havlar' 'hızlıdır' 'kedi' 'koşar' 'köpek' 'miyavlar' 'sevimlidir' 've'\n",
            " 'çok']\n",
            "BoW Matrisi:\n",
            " [[0 1 2 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 1 0 1]\n",
            " [1 0 1 0 1 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "3.TF-IDF (Term Frequency – Inverse Document Frequency) Skorlama\n",
        "\n"
      ],
      "metadata": {
        "id": "ReYfrmopz0Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "documents = [\n",
        "    \"Kedi hızlıdır ve kedi koşar.\",\n",
        "    \"Kedi çok sevimlidir.\",\n",
        "    \"Köpek havlar, kedi miyavlar.\"\n",
        "]\n",
        "\n",
        "# TF-IDF modeli\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Kelime Sözlüğü:\", vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrisi:\\n\", X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kZM_9eczy2-",
        "outputId": "33ff448a-bd66-4c33-88e3-10306a799eaa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelime Sözlüğü: ['havlar' 'hızlıdır' 'kedi' 'koşar' 'köpek' 'miyavlar' 'sevimlidir' 've'\n",
            " 'çok']\n",
            "TF-IDF Matrisi:\n",
            " [[0.         0.4769856  0.56343076 0.4769856  0.         0.\n",
            "  0.         0.4769856  0.        ]\n",
            " [0.         0.         0.38537163 0.         0.         0.\n",
            "  0.65249088 0.         0.65249088]\n",
            " [0.54645401 0.         0.32274454 0.         0.54645401 0.54645401\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram**"
      ],
      "metadata": {
        "id": "lk-eb2Bjz7-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "def generate_ngrams(text, n):\n",
        "    \"\"\"Generate n-grams from a given text using TreebankWordTokenizer.\"\"\"\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    words = tokenizer.tokenize(text)\n",
        "    n_grams = list(ngrams(words, n))\n",
        "    return n_grams\n",
        "\n",
        "\n",
        "text = \"Today the weather is very nice and sunny.\"\n",
        "\n",
        "\n",
        "unigrams = generate_ngrams(text, 1)\n",
        "bigrams = generate_ngrams(text, 2)\n",
        "trigrams = generate_ngrams(text, 3)\n",
        "\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Bigrams:\", bigrams)\n",
        "print(\"Trigrams:\", trigrams)\n",
        "\n",
        "\n",
        "bigram_counts = Counter(bigrams)\n",
        "print(\"\\nBigram Frequency:\")\n",
        "for bigram, count in bigram_counts.items():\n",
        "    print(f\"{bigram}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmvAS6eHycGZ",
        "outputId": "cbe60478-d88f-4620-9b2b-7d43edcdb6db"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: [('Today',), ('the',), ('weather',), ('is',), ('very',), ('nice',), ('and',), ('sunny',), ('.',)]\n",
            "Bigrams: [('Today', 'the'), ('the', 'weather'), ('weather', 'is'), ('is', 'very'), ('very', 'nice'), ('nice', 'and'), ('and', 'sunny'), ('sunny', '.')]\n",
            "Trigrams: [('Today', 'the', 'weather'), ('the', 'weather', 'is'), ('weather', 'is', 'very'), ('is', 'very', 'nice'), ('very', 'nice', 'and'), ('nice', 'and', 'sunny'), ('and', 'sunny', '.')]\n",
            "\n",
            "Bigram Frequency:\n",
            "('Today', 'the'): 1\n",
            "('the', 'weather'): 1\n",
            "('weather', 'is'): 1\n",
            "('is', 'very'): 1\n",
            "('very', 'nice'): 1\n",
            "('nice', 'and'): 1\n",
            "('and', 'sunny'): 1\n",
            "('sunny', '.'): 1\n"
          ]
        }
      ]
    }
  ]
}